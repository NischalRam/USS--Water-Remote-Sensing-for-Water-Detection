{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8342778,"sourceType":"datasetVersion","datasetId":4955178}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow==2.15.0 gdown","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:57:23.372613Z","iopub.execute_input":"2024-05-21T15:57:23.372874Z","iopub.status.idle":"2024-05-21T15:57:42.584025Z","shell.execute_reply.started":"2024-05-21T15:57:23.372848Z","shell.execute_reply":"2024-05-21T15:57:42.583126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# download the images folder\nimport gdown\nid = \"1Ki0ZV4LXLPDLsQ_knX-9c3gC2xCqbEMA\"\ngdown.download(id=id, output=\"data.zip\")","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:57:46.014475Z","iopub.execute_input":"2024-05-21T15:57:46.015557Z","iopub.status.idle":"2024-05-21T15:57:47.289748Z","shell.execute_reply.started":"2024-05-21T15:57:46.015509Z","shell.execute_reply":"2024-05-21T15:57:47.288866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Full data (image and masks)\n\n# import gdown\n\n# # Google Drive file ID (update this with the new ID of the zip file)\n# file_id = \"1OMkWH3TXdvFKhfUqVfC1sWfTArjJn3pO\"\n\n# # Download the zip file\n# gdown.download(id=file_id, output=\"full_data.zip\", quiet=False)\n\n# # Optionally, you can unzip the downloaded file\n# import zipfile\n# with zipfile.ZipFile(\"full_data.zip\", 'r') as zip_ref:\n#     zip_ref.extractall(\"full_data\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dowbnload the models folder\nurl = \"https://drive.google.com/drive/folders/13zsFUu8JAZzx9tht0beD0KTNai7uZzpM?usp=drive_link\"\ngdown.download_folder(url)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:58:10.700310Z","iopub.execute_input":"2024-05-21T15:58:10.701061Z","iopub.status.idle":"2024-05-21T15:58:22.784294Z","shell.execute_reply.started":"2024-05-21T15:58:10.701022Z","shell.execute_reply":"2024-05-21T15:58:22.783401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unzip the data files\nimport zipfile \n\nwith zipfile.ZipFile(\"data.zip\") as ref:\n    ref.extractall()\n    ref.close()\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:58:22.785718Z","iopub.execute_input":"2024-05-21T15:58:22.786000Z","iopub.status.idle":"2024-05-21T15:58:22.976168Z","shell.execute_reply.started":"2024-05-21T15:58:22.785976Z","shell.execute_reply":"2024-05-21T15:58:22.975244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting up the parent directory as the working directory\nimport sys\nsys.path.append('../')\n\nimport tensorflow as  tf\nfrom keras.models import load_model\nimport os\nfrom PIL import Image\n\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import train_test_split\n","metadata":{"ExecuteTime":{"end_time":"2024-05-06T17:52:40.649013Z","start_time":"2024-05-06T17:52:38.434569Z"},"execution":{"iopub.status.busy":"2024-05-21T15:58:32.768975Z","iopub.execute_input":"2024-05-21T15:58:32.769331Z","iopub.status.idle":"2024-05-21T15:58:51.337671Z","shell.execute_reply.started":"2024-05-21T15:58:32.769305Z","shell.execute_reply":"2024-05-21T15:58:51.336578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n# from tensorflow.keras import backend as K\nimport keras.backend as K \n\ndef iou(y_true, y_pred):\n    def f(y_true, y_pred):\n        intersection = (y_true * y_pred).sum()\n        union = y_true.sum() + y_pred.sum() - intersection\n        x = (intersection + 1e-15) / (union + 1e-15)\n        x = x.astype(np.float32)\n        return x\n    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n\nsmooth = 1e-15\ndef dice_coef(y_true, y_pred):\n    y_true = tf.keras.layers.Flatten()(y_true)\n    y_pred = tf.keras.layers.Flatten()(y_pred)\n    y_true = tf.cast(y_true, dtype=tf.float32)\n    y_pred = tf.cast(y_pred, dtype=tf.float32)\n\n    intersection = tf.reduce_sum(y_true * y_pred)\n    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n\ndef dice_loss(y_true, y_pred):\n    return 1.0 - dice_coef(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:58:51.339823Z","iopub.execute_input":"2024-05-21T15:58:51.341070Z","iopub.status.idle":"2024-05-21T15:58:51.352059Z","shell.execute_reply.started":"2024-05-21T15:58:51.341032Z","shell.execute_reply":"2024-05-21T15:58:51.351131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For new model\nmodel = load_model(\"/kaggle/working/models/deeplabv3_updated.h5\", custom_objects={'dice_coef': dice_coef,\n                                                             'iou': iou})","metadata":{"ExecuteTime":{"end_time":"2024-05-06T17:53:06.931262Z","start_time":"2024-05-06T17:53:05.152886Z"},"execution":{"iopub.status.busy":"2024-05-21T15:58:54.942415Z","iopub.execute_input":"2024-05-21T15:58:54.942792Z","iopub.status.idle":"2024-05-21T15:58:59.420196Z","shell.execute_reply.started":"2024-05-21T15:58:54.942761Z","shell.execute_reply":"2024-05-21T15:58:59.419325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# import glob\n\n# # Define the directory path\n# directory_path = '/kaggle/working/images'\n\n# # Use glob to find all image files with the specified extensions\n# image_files = glob.glob(os.path.join(directory_path, '*.jpg')) + \\\n#               glob.glob(os.path.join(directory_path, '*.jpeg')) + \\\n#               glob.glob(os.path.join(directory_path, '*.png')) + \\\n#               glob.glob(os.path.join(directory_path, '*.gif')) + \\\n#               glob.glob(os.path.join(directory_path, '*.bmp'))\n\n# # Count the number of image files\n# total_images = len(image_files)\n\n# print(f\"Total number of images: {total_images}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:59:34.596027Z","iopub.execute_input":"2024-05-21T15:59:34.596974Z","iopub.status.idle":"2024-05-21T15:59:34.605956Z","shell.execute_reply.started":"2024-05-21T15:59:34.596927Z","shell.execute_reply":"2024-05-21T15:59:34.605041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import expand_dims\nfrom tensorflow.image import resize\n\n# Path to the folder containing images\nfolder_path = \"/kaggle/working/images\"\n\n# Function to load and preprocess images from a folder\ndef load_images_from_folder(folder):\n    images = []\n    for filename in os.listdir(folder):\n        img = cv2.imread(os.path.join(folder, filename))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n        if img is not None:\n            # Resize to 256x256\n            img = resize(img, (256, 256))\n            # Normalize\n            img = img / 255.0\n            images.append(img)\n    return images\n\n# Load images from the folder\nimages = load_images_from_folder(folder_path)\n\n\n\n# Iterate through images\nfor image in images:\n    pred_mask = model.predict(expand_dims(image, axis=0))[0]\n    post_process = (pred_mask[:,:,0] > 0.5).astype('int')\n\n    # Create a new figure for each image\n    plt.figure(figsize=(15, 5))\n\n    # Plot original image\n    plt.subplot(1, 3, 1)\n    plt.imshow(image)\n    plt.title(\"Original Image\")\n    plt.axis('off')\n\n    # Plot predicted mask\n    plt.subplot(1, 3, 2)\n    plt.imshow(pred_mask.squeeze())\n    plt.title(\"Predicted Mask\")\n    plt.axis('off')\n\n    # Plot post-processed mask\n    plt.subplot(1, 3, 3)\n    plt.imshow(post_process)\n    plt.title(\"Post-Processed Mask\")\n    plt.axis('off')\n\n    # Show the figure\n    plt.tight_layout()\n    plt.show()\n","metadata":{"ExecuteTime":{"end_time":"2024-05-06T17:53:25.651097Z","start_time":"2024-05-06T17:53:11.566325Z"},"execution":{"iopub.status.busy":"2024-05-12T21:18:03.950647Z","iopub.execute_input":"2024-05-12T21:18:03.951096Z","iopub.status.idle":"2024-05-12T21:18:40.499125Z","shell.execute_reply.started":"2024-05-12T21:18:03.951067Z","shell.execute_reply":"2024-05-12T21:18:40.498168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimages, filenames = load_images_from_folder(folder_path)\n\n# Create the mask_output folder if it doesn't exist\nmask_output_folder = \"/kaggle/working/mask_output\"\nos.makedirs(mask_output_folder, exist_ok=True)\n\n# Iterate through images and filenames\nfor image, filename in zip(images, filenames):\n    pred_mask = model.predict(expand_dims(image, axis=0))[0]\n    post_process = (pred_mask[:,:,0] > 0.5).astype('int')\n\n    # Save post-processed mask\n    mask_filename = os.path.splitext(filename)[0] + \"_mask.png\"  # Append \"_mask\" to original filename\n    mask_filepath = os.path.join(mask_output_folder, mask_filename)\n    cv2.imwrite(mask_filepath, post_process * 255)  # Save the mask as a binary image\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T16:56:27.077896Z","iopub.execute_input":"2024-05-21T16:56:27.078803Z","iopub.status.idle":"2024-05-21T16:56:28.010943Z","shell.execute_reply.started":"2024-05-21T16:56:27.078771Z","shell.execute_reply":"2024-05-21T16:56:28.009737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# only process 3 images\n\nimport os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import expand_dims\nfrom tensorflow.image import resize\n\n# Path to the folder containing images\nfolder_path = \"/kaggle/working/images\"\n\n# Function to load and preprocess images from a folder\ndef load_images_from_folder(folder):\n    images = []\n    for filename in os.listdir(folder):\n        img = cv2.imread(os.path.join(folder, filename))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n        if img is not None:\n            # Resize to 256x256\n            img = resize(img, (256, 256))\n            # Normalize\n            img = img / 255.0\n            images.append(img)\n    return images\n\n# Load images from the folder\nimages = load_images_from_folder(folder_path)\n\n\n# Only process the first 3 images\nimages = images[:3]\n\n\n# Iterate through images\nfor image in images:\n    pred_mask = model.predict(expand_dims(image, axis=0))[0]\n    post_process = (pred_mask[:,:,0] > 0.5).astype('int')\n\n    # Create a new figure for each image\n    plt.figure(figsize=(15, 5))\n\n    # Plot original image\n    plt.subplot(1, 3, 1)\n    plt.imshow(image)\n    plt.title(\"Original Image\")\n    plt.axis('off')\n\n    # Plot predicted mask\n    plt.subplot(1, 3, 2)\n    plt.imshow(pred_mask.squeeze())\n    plt.title(\"Predicted Mask\")\n    plt.axis('off')\n\n    # Plot post-processed mask\n    plt.subplot(1, 3, 3)\n    plt.imshow(post_process)\n    plt.title(\"Post-Processed Mask\")\n    plt.axis('off')\n\n    # Show the figure\n    plt.tight_layout()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T16:01:36.929248Z","iopub.execute_input":"2024-05-21T16:01:36.930012Z","iopub.status.idle":"2024-05-21T16:01:46.651845Z","shell.execute_reply.started":"2024-05-21T16:01:36.929983Z","shell.execute_reply":"2024-05-21T16:01:46.650775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import expand_dims\nfrom tensorflow.image import resize\n\n# Path to the folder containing images\nfolder_path = \"/kaggle/working/images\"\n\n# Function to load and preprocess images from a folder\ndef load_images_from_folder(folder):\n    images = []\n    filenames = []\n    for filename in os.listdir(folder):\n        img = cv2.imread(os.path.join(folder, filename))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        if img is not None:\n            # Resize to 256x256\n            img = resize(img, (256, 256))\n            # Normalize\n            img = img / 255.0\n            images.append(img)\n            filenames.append(filename)\n    return images, filenames\n\n# Load images from the folder\nimages, filenames = load_images_from_folder(folder_path)\n\n# Create the mask_output folder if it doesn't exist\nmask_output_folder = \"/kaggle/working/mask_output\"\nos.makedirs(mask_output_folder, exist_ok=True)\n\n# Iterate through images and filenames\nfor image, filename in zip(images, filenames):\n    pred_mask = model.predict(expand_dims(image, axis=0))[0]\n    post_process = (pred_mask[:,:,0] > 0.5).astype('int')\n\n    # Save post-processed mask\n    mask_filename = os.path.splitext(filename)[0] + \"_mask.png\"  # Append \"_mask\" to original filename\n    mask_filepath = os.path.join(mask_output_folder, mask_filename)\n    cv2.imwrite(mask_filepath, post_process * 255)  # Save the mask as a binary image\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T16:57:24.573577Z","iopub.execute_input":"2024-05-21T16:57:24.573949Z","iopub.status.idle":"2024-05-21T16:57:28.935914Z","shell.execute_reply.started":"2024-05-21T16:57:24.573922Z","shell.execute_reply":"2024-05-21T16:57:28.935116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Final Code to process large images, splits into 1000 * 1000 then resize to 256\n\nimport os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import expand_dims\nfrom tensorflow.image import resize\nimport tensorflow as tf\n\n# Path to the large image\nlarge_image_path = \"/kaggle/input/chicago/41.612898753320216 -87.30889155863774_Chicago_pilot_1.tif\"\n\n# Path to save predicted masks\noutput_folder = \"/kaggle/working/\"\n\n# Function to predict masks for large image patches\ndef predict_masks(image, model):\n    # Define patch size\n    patch_size = (1000, 1000)\n    \n    # Calculate number of patches in each dimension\n    num_patches_h = image.shape[0] // patch_size[0] + 1\n    num_patches_w = image.shape[1] // patch_size[1] + 1\n    \n    # Initialize empty array to store predicted masks\n    predicted_masks = np.zeros(image.shape[:2], dtype=np.float32)\n    \n    # Iterate through patches\n    for i in range(num_patches_h):\n        for j in range(num_patches_w):\n            # Calculate patch coordinates\n            start_h = i * patch_size[0]\n            end_h = min(start_h + patch_size[0], image.shape[0])\n            start_w = j * patch_size[1]\n            end_w = min(start_w + patch_size[1], image.shape[1])\n            \n            # Extract patch\n            patch = image[start_h:end_h, start_w:end_w]\n            \n            # Resize and normalize patch\n            patch = resize(patch, (256, 256)) / 255.0\n            \n            # Predict mask for patch\n            pred_mask = model.predict(expand_dims(patch, axis=0))[0]\n            post_process = (pred_mask[:,:,0] > 0.8).astype('float32')\n            \n            # Expand dimensions to make it 3D\n            post_process = tf.expand_dims(post_process, axis=-1)\n            \n            # Resize the post_process array to match patch size\n            post_process = tf.image.resize(post_process, [end_h - start_h, end_w - start_w])\n            \n            # Remove dimensions of size 1 from the shape of the tensor\n            post_process = tf.squeeze(post_process)\n            \n            # Place predicted patch into correct location in the array\n            predicted_masks[start_h:end_h, start_w:end_w] = post_process.numpy()\n            \n    return predicted_masks\n\n\n# Load the large image\nlarge_image = cv2.imread(large_image_path)\nlarge_image_rgb = cv2.cvtColor(large_image, cv2.COLOR_BGR2RGB)\n\n# Predict masks for the large image\npredicted_mask = predict_masks(large_image_rgb, model)\n\n# Save predicted mask\nos.makedirs(output_folder, exist_ok=True)\noutput_path = os.path.join(output_folder, \"patch1000 sen 8 41.612898753320216 -87.30889155863774_Chicago_pilot_1_predicted_mask.png\")\nplt.imsave(output_path, predicted_mask, cmap='gray')\n\nprint(\"Prediction saved at:\", output_path)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code to process large images, splits into 1000 * 1000 then resize to 256\n\nimport os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import expand_dims\nfrom tensorflow.image import resize\nimport tensorflow as tf\n\n# Path to the large image\nlarge_image_path = \"/kaggle/input/chicago/41.612898753320216 -87.30889155863774_Chicago_pilot_1.tif\"\n\n# Path to save predicted masks\noutput_folder = \"/kaggle/working/\"\n\n# Function to predict masks for large image patches\ndef predict_masks(image, model):\n    # Define patch size\n    patch_size = (1000, 1000)\n    \n    # Calculate number of patches in each dimension\n    num_patches_h = image.shape[0] // patch_size[0] + 1\n    num_patches_w = image.shape[1] // patch_size[1] + 1\n    \n    # Initialize empty array to store predicted masks\n    predicted_masks = np.zeros(image.shape[:2], dtype=np.float32)\n    \n    # Iterate through patches\n    for i in range(num_patches_h):\n        for j in range(num_patches_w):\n            # Calculate patch coordinates\n            start_h = i * patch_size[0]\n            end_h = min(start_h + patch_size[0], image.shape[0])\n            start_w = j * patch_size[1]\n            end_w = min(start_w + patch_size[1], image.shape[1])\n            \n            # Extract patch\n            patch = image[start_h:end_h, start_w:end_w]\n            \n            # Resize and normalize patch\n            patch = resize(patch, (256, 256)) / 255.0\n            \n            # Predict mask for patch\n            pred_mask = model.predict(expand_dims(patch, axis=0))[0]\n            post_process = (pred_mask[:,:,0] > 0.5).astype('float32')\n            \n            # Expand dimensions to make it 3D\n            post_process = tf.expand_dims(post_process, axis=-1)\n            \n            # Resize the post_process array to match patch size\n            post_process = tf.image.resize(post_process, [end_h - start_h, end_w - start_w])\n            \n            # Remove dimensions of size 1 from the shape of the tensor\n            post_process = tf.squeeze(post_process)\n            \n            # Place predicted patch into correct location in the array\n            predicted_masks[start_h:end_h, start_w:end_w] = post_process.numpy()\n            \n    return predicted_masks\n\n\n# Load the large image\nlarge_image = cv2.imread(large_image_path)\nlarge_image_rgb = cv2.cvtColor(large_image, cv2.COLOR_BGR2RGB)\n\n# Predict masks for the large image\npredicted_mask = predict_masks(large_image_rgb, model)\n\n# Save predicted mask\nos.makedirs(output_folder, exist_ok=True)\noutput_path = os.path.join(output_folder, \"patch100 sen 5 41.612898753320216 -87.30889155863774_Chicago_pilot_1_predicted_mask.png\")\nplt.imsave(output_path, predicted_mask, cmap='gray')\n\nprint(\"Prediction saved at:\", output_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-12T21:45:08.844207Z","iopub.execute_input":"2024-05-12T21:45:08.844937Z","iopub.status.idle":"2024-05-12T21:46:08.599703Z","shell.execute_reply.started":"2024-05-12T21:45:08.844906Z","shell.execute_reply":"2024-05-12T21:46:08.598561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code to process large images, but splits into 255's\n\nimport os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import expand_dims\nfrom tensorflow.image import resize\n\n# Path to the large image\nlarge_image_path = \"/kaggle/input/chicago/41.612898753320216 -87.30889155863774_Chicago_pilot_1.tif\"\n\n# Path to save predicted masks\noutput_folder = \"/kaggle/working/\"\n\n# Function to predict masks for large image patches\ndef predict_masks(image, model):\n    # Define patch size\n    patch_size = (256, 256)\n    \n    # Calculate number of patches in each dimension\n    num_patches_h = image.shape[0] // patch_size[0] + 1\n    num_patches_w = image.shape[1] // patch_size[1] + 1\n    \n    # Initialize empty array to store predicted masks\n    predicted_masks = np.zeros(image.shape[:2], dtype=np.float32)\n    \n    # Iterate through patches\n    for i in range(num_patches_h):\n        for j in range(num_patches_w):\n            # Calculate patch coordinates\n            start_h = i * patch_size[0]\n            end_h = min(start_h + patch_size[0], image.shape[0])\n            start_w = j * patch_size[1]\n            end_w = min(start_w + patch_size[1], image.shape[1])\n            \n            # Extract patch\n            patch = image[start_h:end_h, start_w:end_w]\n            \n            # Resize and normalize patch\n            patch = resize(patch, (256, 256)) / 255.0\n            \n            # Predict mask for patch\n            pred_mask = model.predict(expand_dims(patch, axis=0))[0]\n            post_process = (pred_mask[:,:,0] > 0.5).astype('float32')\n            \n            # Place predicted patch into correct location in the array\n            predicted_masks[start_h:end_h, start_w:end_w] = post_process[:end_h-start_h, :end_w-start_w]\n            \n    return predicted_masks\n\n\n# Load the large image\nlarge_image = cv2.imread(large_image_path)\nlarge_image_rgb = cv2.cvtColor(large_image, cv2.COLOR_BGR2RGB)\n\n# Predict masks for the large image\npredicted_mask = predict_masks(large_image_rgb, model)\n\n# Save predicted mask\nos.makedirs(output_folder, exist_ok=True)\noutput_path = os.path.join(output_folder, \"41.612898753320216 -87.30889155863774_Chicago_pilot_1_predicted_mask.png\")\nplt.imsave(output_path, predicted_mask, cmap='gray')\n\nprint(\"Prediction saved at:\", output_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-12T21:35:42.086279Z","iopub.execute_input":"2024-05-12T21:35:42.087588Z","iopub.status.idle":"2024-05-12T21:36:00.433441Z","shell.execute_reply.started":"2024-05-12T21:35:42.087522Z","shell.execute_reply":"2024-05-12T21:36:00.432085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}