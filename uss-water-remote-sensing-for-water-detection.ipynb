{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow==2.15.0 gdown","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:39:58.119593Z","iopub.execute_input":"2024-05-21T14:39:58.120419Z","iopub.status.idle":"2024-05-21T14:40:10.547114Z","shell.execute_reply.started":"2024-05-21T14:39:58.120387Z","shell.execute_reply":"2024-05-21T14:40:10.546137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# download the images folder 40 images\nimport gdown\nid = \"1Ki0ZV4LXLPDLsQ_knX-9c3gC2xCqbEMA\"\ngdown.download(id=id, output=\"data.zip\")","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:40:10.549362Z","iopub.execute_input":"2024-05-21T14:40:10.550270Z","iopub.status.idle":"2024-05-21T14:40:11.324351Z","shell.execute_reply.started":"2024-05-21T14:40:10.550217Z","shell.execute_reply":"2024-05-21T14:40:11.323543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Full data (image and masks)\n\n# import gdown\n\n# # Google Drive file ID (update this with the new ID of the zip file)\n# file_id = \"1OMkWH3TXdvFKhfUqVfC1sWfTArjJn3pO\"\n\n# # Download the zip file\n# gdown.download(id=file_id, output=\"full_data.zip\", quiet=False)\n\n# # Optionally, you can unzip the downloaded file\n# import zipfile\n# with zipfile.ZipFile(\"full_data.zip\", 'r') as zip_ref:\n#     zip_ref.extractall(\"full_data\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:28:12.442903Z","iopub.execute_input":"2024-05-14T03:28:12.443283Z","iopub.status.idle":"2024-05-14T03:28:25.620255Z","shell.execute_reply.started":"2024-05-14T03:28:12.443253Z","shell.execute_reply":"2024-05-14T03:28:25.619194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dowbnload the models folder\nurl = \"https://drive.google.com/drive/folders/13zsFUu8JAZzx9tht0beD0KTNai7uZzpM?usp=drive_link\"\ngdown.download_folder(url)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:40:20.023463Z","iopub.execute_input":"2024-05-21T14:40:20.024168Z","iopub.status.idle":"2024-05-21T14:40:30.646954Z","shell.execute_reply.started":"2024-05-21T14:40:20.024118Z","shell.execute_reply":"2024-05-21T14:40:30.645848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unzip the data files\nimport zipfile \n\nwith zipfile.ZipFile(\"data.zip\") as ref:\n    ref.extractall()\n    ref.close()\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:40:30.649046Z","iopub.execute_input":"2024-05-21T14:40:30.649431Z","iopub.status.idle":"2024-05-21T14:40:30.829385Z","shell.execute_reply.started":"2024-05-21T14:40:30.649399Z","shell.execute_reply":"2024-05-21T14:40:30.828563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# import glob\n\n# # Define the directory path\n# directory_path = '/kaggle/working/images'\n\n# # Use glob to find all image files with the specified extensions\n# image_files = glob.glob(os.path.join(directory_path, '*.jpg')) + \\\n#               glob.glob(os.path.join(directory_path, '*.jpeg')) + \\\n#               glob.glob(os.path.join(directory_path, '*.png')) + \\\n#               glob.glob(os.path.join(directory_path, '*.gif')) + \\\n#               glob.glob(os.path.join(directory_path, '*.bmp'))\n\n# # Count the number of image files\n# total_images = len(image_files)\n\n# print(f\"Total number of images: {total_images}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:40:30.830558Z","iopub.execute_input":"2024-05-21T14:40:30.830860Z","iopub.status.idle":"2024-05-21T14:40:30.835433Z","shell.execute_reply.started":"2024-05-21T14:40:30.830835Z","shell.execute_reply":"2024-05-21T14:40:30.834465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting up the parent directory as the working directory\n\n\nimport tensorflow as  tf\nfrom keras.models import load_model\nimport os\nfrom PIL import Image\n\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import train_test_split\n# physical_devices = tf.config.list_physical_devices('GPU')\n\n# tf.config.set_visible_devices(physical_devices[1:], 'GPU')","metadata":{"ExecuteTime":{"end_time":"2024-05-06T17:48:14.730686Z","start_time":"2024-05-06T17:48:12.720741Z"},"execution":{"iopub.status.busy":"2024-05-21T14:40:30.837713Z","iopub.execute_input":"2024-05-21T14:40:30.838377Z","iopub.status.idle":"2024-05-21T14:40:30.849389Z","shell.execute_reply.started":"2024-05-21T14:40:30.838346Z","shell.execute_reply":"2024-05-21T14:40:30.848702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nclass UNet(tf.keras.Model):\n    def __init__(self, in_channels, num_classes):\n        super(UNet, self).__init__()\n        self.down_convolution_1 = DownSample(in_channels, 64)\n        self.down_convolution_2 = DownSample(64, 128)\n        self.down_convolution_3 = DownSample(128, 256)\n        self.down_convolution_4 = DownSample(256, 512)\n\n        self.bottle_neck = DoubleConv(512, 1024)\n\n        self.up_convolution_1 = UpSample(1024, 512)\n        self.up_convolution_2 = UpSample(512, 256)\n        self.up_convolution_3 = UpSample(256, 128)\n        self.up_convolution_4 = UpSample(128, 64)\n\n        self.out = tf.keras.layers.Conv2D(num_classes, kernel_size=1)\n\n    def call(self, x):\n        down_1, p1 = self.down_convolution_1(x)\n        down_2, p2 = self.down_convolution_2(p1)\n        down_3, p3 = self.down_convolution_3(p2)\n        down_4, p4 = self.down_convolution_4(p3)\n\n        b = self.bottle_neck(p4)\n\n        up_1 = self.up_convolution_1(b, down_4)\n        up_2 = self.up_convolution_2(up_1, down_3)\n        up_3 = self.up_convolution_3(up_2, down_2)\n        up_4 = self.up_convolution_4(up_3, down_1)\n\n        out = self.out(up_4)\n        return out\n\n\nclass DoubleConv(tf.keras.Model):\n    def __init__(self, in_channels, out_channels):\n        super(DoubleConv, self).__init__()\n        self.conv_op = tf.keras.Sequential([\n            tf.keras.layers.Conv2D(out_channels, kernel_size=3, padding='same'),\n            tf.keras.layers.ReLU(),\n            tf.keras.layers.Conv2D(out_channels, kernel_size=3, padding='same'),\n            tf.keras.layers.ReLU()\n        ])\n\n    def call(self, x):\n        return self.conv_op(x)\n\n\nclass DownSample(tf.keras.Model):\n    def __init__(self, in_channels, out_channels):\n        super(DownSample, self).__init__()\n        self.conv = DoubleConv(in_channels, out_channels)\n        self.pool = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2))\n\n    def call(self, x):\n        down = self.conv(x)\n        p = self.pool(down)\n\n        return down, p\n\n\nclass UpSample(tf.keras.Model):\n    def __init__(self, in_channels, out_channels):\n        super(UpSample, self).__init__()\n        self.up = tf.keras.layers.Conv2DTranspose(in_channels // 2, kernel_size=2, strides=2)\n        self.conv = DoubleConv(in_channels, out_channels)\n\n    def call(self, x1, x2):\n        x1 = self.up(x1)\n        x = tf.concat([x1, x2], axis=-1)\n        return self.conv(x)\n","metadata":{"ExecuteTime":{"end_time":"2024-05-06T17:48:21.934002Z","start_time":"2024-05-06T17:48:21.913425Z"},"execution":{"iopub.status.busy":"2024-05-21T14:40:30.850456Z","iopub.execute_input":"2024-05-21T14:40:30.850721Z","iopub.status.idle":"2024-05-21T14:40:30.869705Z","shell.execute_reply.started":"2024-05-21T14:40:30.850699Z","shell.execute_reply":"2024-05-21T14:40:30.868806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For new model\nmodel = load_model(\"/kaggle/working/models/unet_model_512.keras\", custom_objects={'UNet' : UNet})","metadata":{"ExecuteTime":{"end_time":"2024-05-06T17:48:49.214994Z","start_time":"2024-05-06T17:48:22.417020Z"},"execution":{"iopub.status.busy":"2024-05-21T14:40:30.870915Z","iopub.execute_input":"2024-05-21T14:40:30.871271Z","iopub.status.idle":"2024-05-21T14:40:58.190064Z","shell.execute_reply.started":"2024-05-21T14:40:30.871238Z","shell.execute_reply":"2024-05-21T14:40:58.189296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import expand_dims\nfrom tensorflow.image import resize\n\n# Path to the folder containing images\nfolder_path = \"/kaggle/working/images\"\n\n# Function to load and preprocess images from a folder\ndef load_images_from_folder(folder):\n    images = []\n    for filename in os.listdir(folder):\n        img = cv2.imread(os.path.join(folder, filename))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n        if img is not None:\n            # Resize to 256x256\n            img = resize(img, (512, 512))\n            # Normalize\n            img = img / 255.0\n            images.append(img)\n    return images\n\n# Load images from the folder\nimages = load_images_from_folder(folder_path)\n\n# Iterate through images\nfor image in images:\n    pred_mask = model.predict(expand_dims(image, axis=0))[0]\n    post_process = (pred_mask[:,:,0] > 0.5).astype('int')\n\n    # Create a new figure for each image\n    plt.figure(figsize=(15, 5))\n\n    # Plot original image\n    plt.subplot(1, 3, 1)\n    plt.imshow(image)\n    plt.title(\"Original Image\")\n    plt.axis('off')\n\n    # Plot predicted mask\n    plt.subplot(1, 3, 2)\n    plt.imshow(pred_mask.squeeze())\n    plt.title(\"Predicted Mask\")\n    plt.axis('off')\n\n    # Plot post-processed mask\n    plt.subplot(1, 3, 3)\n    plt.imshow(post_process)\n    plt.title(\"Post-Processed Mask\")\n    plt.axis('off')\n\n    # Show the figure\n    plt.tight_layout()\n    plt.show()\n","metadata":{"ExecuteTime":{"end_time":"2024-05-06T17:49:06.834038Z","start_time":"2024-05-06T17:48:49.216341Z"},"execution":{"iopub.status.busy":"2024-05-21T14:25:28.513207Z","iopub.execute_input":"2024-05-21T14:25:28.513556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the mask_output folder if it doesn't exist\nmask_output_folder = \"/kaggle/working/mask_output\"\nos.makedirs(mask_output_folder, exist_ok=True)\n\n# Iterate through images\nfor filename, image in zip(os.listdir(folder_path), images):\n    # Predict mask\n    pred_mask = model.predict(expand_dims(image, axis=0))[0]\n    post_process = (pred_mask[:, :, 0] > 0.5).astype('int')\n\n    # Save post-processed mask\n    mask_filename = os.path.splitext(filename)[0] + \"_mask.png\"  # Append \"_mask\" to original filename\n    mask_filepath = os.path.join(mask_output_folder, mask_filename)\n    cv2.imwrite(mask_filepath, post_process * 255)  # Save the mask as a binary image\n\n#     # Create a new figure for each image\n#     plt.figure(figsize=(15, 5))\n\n#     # Plot original image\n#     plt.subplot(1, 3, 1)\n#     plt.imshow(image)\n#     plt.title(\"Original Image\")\n#     plt.axis('off')\n\n#     # Plot predicted mask\n#     plt.subplot(1, 3, 2)\n#     plt.imshow(pred_mask.squeeze())\n#     plt.title(\"Predicted Mask\")\n#     plt.axis('off')\n\n#     # Plot post-processed mask\n#     plt.subplot(1, 3, 3)\n#     plt.imshow(post_process)\n#     plt.title(\"Post-Processed Mask\")\n#     plt.axis('off')\n\n    # Save the figure with the same filename as the original image\n#     output_filename = os.path.splitext(filename)[0] + \"_output.png\"  # Append \"_output\" to original filename\n#     output_filepath = os.path.join(mask_output_folder, output_filename)\n#     plt.savefig(output_filepath)\n\n#     # Show the figure\n#     plt.tight_layout()\n#     plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:41:47.154709Z","iopub.execute_input":"2024-05-21T14:41:47.155465Z","iopub.status.idle":"2024-05-21T14:42:15.788576Z","shell.execute_reply.started":"2024-05-21T14:41:47.155428Z","shell.execute_reply":"2024-05-21T14:42:15.787667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\n\nmask_output_folder = \"/kaggle/working/mask_output_1000\"\nos.makedirs(mask_output_folder, exist_ok=True)\n\n# Resize the images to 1000x1000\nresized_images = [cv2.resize(img, (1000, 1000)) for img in images]\n\n# Iterate through images\nfor filename, image in zip(os.listdir(folder_path), resized_images):\n    # Predict mask\n    pred_mask = model.predict(expand_dims(image, axis=0))[0]\n    post_process = (pred_mask[:, :, 0] > 0.5).astype('int')\n\n#     # Save post-processed mask\n#     mask_filename = os.path.splitext(filename)[0] + \"_mask.png\"  # Append \"_mask\" to original filename\n#     mask_filepath = os.path.join(mask_output_folder, mask_filename)\n#     cv2.imwrite(mask_filepath, post_process * 255)  # Save the mask as a binary image\n\n    # Save resized image\n    output_filename = os.path.splitext(filename)[0] + \"_output.png\"  # Append \"_output\" to original filename\n    output_filepath = os.path.join(mask_output_folder, output_filename)\n    cv2.imwrite(output_filepath, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))  # Save the resized image\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:18:22.768711Z","iopub.execute_input":"2024-05-21T15:18:22.769510Z","iopub.status.idle":"2024-05-21T15:18:23.530533Z","shell.execute_reply.started":"2024-05-21T15:18:22.769478Z","shell.execute_reply":"2024-05-21T15:18:23.529175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\n\nmask_output_folder = \"/kaggle/working/mask_output_1000\"\nos.makedirs(mask_output_folder, exist_ok=True)\n\n# Ensure images are loaded correctly\nif not all(isinstance(img, np.ndarray) for img in images):\n    raise ValueError(\"Images are not loaded as NumPy arrays.\")\n\n# Ensure images are of correct shape\nif not all(img.shape[0] > 0 and img.shape[1] > 0 for img in images):\n    raise ValueError(\"Some images have invalid shapes.\")\n\n# Ensure images are of correct data type\nif not all(img.dtype == np.uint8 for img in images):\n    raise ValueError(\"Some images have invalid data type.\")\n\n# Resize the images to 1000x1000\nresized_images = [cv2.resize(img, (1000, 1000)) for img in images]\n\n# Iterate through images\nfor filename, image in zip(os.listdir(folder_path), resized_images):\n    # Predict mask\n    pred_mask = model.predict(expand_dims(image, axis=0))[0]\n    post_process = (pred_mask[:, :, 0] > 0.5).astype('int')\n\n    # Save post-processed mask\n    mask_filename = os.path.splitext(filename)[0] + \"_mask.png\"  # Append \"_mask\" to original filename\n    mask_filepath = os.path.join(mask_output_folder, mask_filename)\n    cv2.imwrite(mask_filepath, post_process * 255)  # Save the mask as a binary image\n\n    # Save resized image\n    output_filename = os.path.splitext(filename)[0] + \"_output.png\"  # Append \"_output\" to original filename\n    output_filepath = os.path.join(mask_output_folder, output_filename)\n    cv2.imwrite(output_filepath, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))  # Save the resized image\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:19:27.604917Z","iopub.execute_input":"2024-05-21T15:19:27.605743Z","iopub.status.idle":"2024-05-21T15:19:27.657383Z","shell.execute_reply.started":"2024-05-21T15:19:27.605706Z","shell.execute_reply":"2024-05-21T15:19:27.656013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# only process 3 images\n\nimport os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import expand_dims\nfrom tensorflow.image import resize\n\n# Path to the folder containing images\nfolder_path = \"/kaggle/working/images\"\n\n# Function to load and preprocess images from a folder\ndef load_images_from_folder(folder):\n    images = []\n    for filename in os.listdir(folder):\n        img = cv2.imread(os.path.join(folder, filename))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n        if img is not None:\n            # Resize to 256x256\n            img = resize(img, (512, 512))\n            # Normalize\n            img = img / 255.0\n            images.append(img)\n    return images\n\n# Load images from the folder\nimages = load_images_from_folder(folder_path)\n\n# Only process the first 3 images\nimages_to_process = images[:3]\n\n# Iterate through selected images\nfor i, image in enumerate(images_to_process):\n    print(f\"Processing image {i+1} of {len(images_to_process)}\")\n    pred_mask = model.predict(expand_dims(image, axis=0))[0]\n    post_process = (pred_mask[:,:,0] > 0.5).astype('int')\n\n    # Create a new figure for each image\n    plt.figure(figsize=(15, 5))\n\n    # Plot original image\n    plt.subplot(1, 3, 1)\n    plt.imshow(image)\n    plt.title(\"Original Image\")\n    plt.axis('off')\n\n    # Plot predicted mask\n    plt.subplot(1, 3, 2)\n    plt.imshow(pred_mask.squeeze())\n    plt.title(\"Predicted Mask\")\n    plt.axis('off')\n\n    # Plot post-processed mask\n    plt.subplot(1, 3, 3)\n    plt.imshow(post_process)\n    plt.title(\"Post-Processed Mask\")\n    plt.axis('off')\n\n    # Show the figure\n    plt.tight_layout()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:37:24.908711Z","iopub.execute_input":"2024-05-21T14:37:24.909468Z","iopub.status.idle":"2024-05-21T14:37:28.207022Z","shell.execute_reply.started":"2024-05-21T14:37:24.909435Z","shell.execute_reply":"2024-05-21T14:37:28.206010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import expand_dims\nfrom tensorflow.image import resize\n\n# Path to the folder containing images\nfolder_path = \"/kaggle/working/images\"\n\n# Function to load and preprocess images from a folder\ndef load_images_from_folder(folder):\n    images = []\n    for filename in os.listdir(folder):\n        img = cv2.imread(os.path.join(folder, filename))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n        if img is not None:\n            # Resize to 256x256\n            img = resize(img, (512, 512))\n            # Normalize\n            img = img / 255.0\n            images.append(img)\n    return images\n\n# Load images from the folder\nimages = load_images_from_folder(folder_path)\n\n# Iterate through images\nfor image in images:\n    pred_mask = model.predict(expand_dims(image, axis=0))[0]\n    post_process = (pred_mask[:,:,0] > 0.5).astype('int')\n\n    # Create a new figure for each image\n    plt.figure(figsize=(15, 5))\n\n    # Plot original image\n    plt.subplot(1, 3, 1)\n    plt.imshow(image)\n    plt.title(\"Original Image\")\n    plt.axis('off')\n\n    # Plot predicted mask\n    plt.subplot(1, 3, 2)\n    plt.imshow(pred_mask.squeeze())\n    plt.title(\"Predicted Mask\")\n    plt.axis('off')\n\n    # Plot post-processed mask\n    plt.subplot(1, 3, 3)\n    plt.imshow(post_process)\n    plt.title(\"Post-Processed Mask\")\n    plt.axis('off')\n\n    # Show the figure\n    plt.tight_layout()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-14T02:55:30.766902Z","iopub.execute_input":"2024-05-14T02:55:30.767585Z","iopub.status.idle":"2024-05-14T02:56:10.504009Z","shell.execute_reply.started":"2024-05-14T02:55:30.767551Z","shell.execute_reply":"2024-05-14T02:56:10.503145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code to process large images, splits into 1000 * 1000 then resize to 256\n\nimport os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import expand_dims\nfrom tensorflow.image import resize\nimport tensorflow as tf\n\n# Path to the large image\nlarge_image_path = \"/kaggle/input/chicago/41.612898753320216 -87.30889155863774_Chicago_pilot_1.tif\"\n\n# Path to save predicted masks\noutput_folder = \"/kaggle/working/\"\n\n# Function to predict masks for large image patches\ndef predict_masks(image, model):\n    # Define patch size\n    patch_size = (1000, 1000)\n    \n    # Calculate number of patches in each dimension\n    num_patches_h = image.shape[0] // patch_size[0] + 1\n    num_patches_w = image.shape[1] // patch_size[1] + 1\n    \n    # Initialize empty array to store predicted masks\n    predicted_masks = np.zeros(image.shape[:2], dtype=np.float32)\n    \n    # Iterate through patches\n    for i in range(num_patches_h):\n        for j in range(num_patches_w):\n            # Calculate patch coordinates\n            start_h = i * patch_size[0]\n            end_h = min(start_h + patch_size[0], image.shape[0])\n            start_w = j * patch_size[1]\n            end_w = min(start_w + patch_size[1], image.shape[1])\n            \n            # Extract patch\n            patch = image[start_h:end_h, start_w:end_w]\n            \n            # Resize and normalize patch\n            patch = resize(patch, (256, 256)) / 255.0\n            \n            # Predict mask for patch\n            pred_mask = model.predict(expand_dims(patch, axis=0))[0]\n            post_process = (pred_mask[:,:,0] > 0.5).astype('float32')\n            \n            # Expand dimensions to make it 3D\n            post_process = tf.expand_dims(post_process, axis=-1)\n            \n            # Resize the post_process array to match patch size\n            post_process = tf.image.resize(post_process, [end_h - start_h, end_w - start_w])\n            \n            # Remove dimensions of size 1 from the shape of the tensor\n            post_process = tf.squeeze(post_process)\n            \n            # Place predicted patch into correct location in the array\n            predicted_masks[start_h:end_h, start_w:end_w] = post_process.numpy()\n            \n    return predicted_masks\n\n\n# Load the large image\nlarge_image = cv2.imread(large_image_path)\nlarge_image_rgb = cv2.cvtColor(large_image, cv2.COLOR_BGR2RGB)\n\n# Predict masks for the large image\npredicted_mask = predict_masks(large_image_rgb, model)\n\n# Save predicted mask\nos.makedirs(output_folder, exist_ok=True)\noutput_path = os.path.join(output_folder, \"patch100 sen 5 41.612898753320216 -87.30889155863774_Chicago_pilot_1_predicted_mask.png\")\nplt.imsave(output_path, predicted_mask, cmap='gray')\n\nprint(\"Prediction saved at:\", output_path)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(UNet, \"UNet-WaterBody.png\", show_shapes=True)","metadata":{},"execution_count":null,"outputs":[]}]}